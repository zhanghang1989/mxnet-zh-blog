---
title: MXNet Gluon上实现跨卡同步Batch Normalization
author: <a href="http://hangzh.com/">张航</a> Amazon AI Applied Scientist
---

很多用户在论坛上，GitHub上，甚至是不同的深度学习平台上，都要求提供跨卡同步Batch Normalization。
我们MXNet团队率先提供了基于Gluon API的实现，并且第一时间提供了一个预览版，希望更快能够得到用户的反馈意见，并且改善API。
在这里我们简要地讲一下Batch Normaliztion的工作方式，以及我们如何实现跨卡同步，还有一些常见的问题回答，
并且欢迎大家到论坛讨论区交流。特别感谢[林海滨](https://github.com/eric-haibin-lin)在后台实现的大力帮助。
[**[预览版代码链接](https://github.com/zhanghang1989/MXNet-Gluon-SyncBN)**]

### 写在前面：为什么要跨卡同步 Batch Normalization
在某些课题任务中，模型的训练非常消耗内存，这样相应分配到每个卡上的批量大小就非常少了，影响模型的收敛效果。之前在我们
在图像语义分割的实验中，[Jerry](http://zhongyuezhang.com/)和我就发现使用大模型的效果反而变差，实际上就是BN在作怪。
最近在物体检测的竞赛中，使用跨卡BN也会很大提高实验效果，所以跨卡BN俨然成为竞赛刷分、发论文的必备神器。

### Batch Normalization如何工作，以及它的标准的实现方式
既然是技术贴，读者很多是深学大牛，为什么还要在这里赘述BatchNorm这个简单概念吗？其实不然，很多做科研的朋友如果没有解决过相关问题，
很容易混淆BN在训练和测试时候的工作方式。记得在17年CVPR的[tutoial](http://deeplearning.csail.mit.edu/)上，
何凯明和RBG两位大神分别在自己的talk上都特意强调了BN的工作原理，可见就算台下都是CV的学者，都有必要复习一遍这些知识。

- 工作原理：

  BN有效地加速了模型训练，加大learning rate，让模型不再过度依赖初始化。它在训练时在网络内部进行归一化（normalization），
  为训练提供了有效的regularization，抑制过拟合，用原作者的话是防止了协方差偏移。这里上一张图来展示训练模式的BN：

  ![](http://hangzh.com/images/bn1.png)

  其中输入样本$$x={x_0,...x_N}$$，其均值为$$\mu=\sum x_i$$，方差为$$\sigma^2=\frac{\sum (x_i-\mu)^2}{N}$$，
  BN的输出$$y_i=\gamma\cdot\frac{x_i-\mu}{\sigma}+\beta$$，$$\gamma\text{与}\beta$$是可学习对参数。
  个人认为，这种强大的效果其实来自于back-propagation时候，来自于**均值和方差对输入样本的梯度**(
  $$\frac{d_\mu}{d_{x_i}} \text{与} \frac{d_\sigma}{d_{x_i}}$$)。
  这也是BN在训练模式与其在测试模式的重要区别，在测试模式（evaluation mode）下，
  使用训练集上累积的均值和方差，在back-propagation的时候他们对输入样本没有梯度（gradient）。

- 数据并行：

  深度学习平台在多卡（GPU）运算的时候都是采用的数据并行（DataParallel），如下图:
  
  ![](http://hangzh.com/images/bn2.png)
  
  每次迭代，输入被等分成多份，然后分别在不同的卡上前向（forward）和后向（backward）运算，并且求出梯度，在迭代完成后合并
  梯度、更新参数，再进行下一次迭代。因为在前向和后向运算的时候，每个卡上的模型是单独运算的，所以相应的Batch Normalization
  也是在卡内完成，所以实际BN所归一化的样本数量仅仅局限于卡内，相当于批量大小（batch-size）减小了。

### 如何实现
跨卡同步BN的关键是在前向运算的时候拿到全局的均值$$\mu$$和方差$$\sigma$$，在后向运算时候得到相应的全局梯度。
最简单的实现方法是先同步求均值，再发回各卡然后同步求方差，但是这样就同步了两次。实际上只需要同步一次就可以，
我们使用了一个非常简单的技巧，把方差表示为$$\sigma^2=\frac{\sum x^2}{N}-\mu^2=\frac{\sum x^2}{N}-\frac{(\sum x_i)^2}{N^2}$$，
附上一张图：
  
![](http://hangzh.com/images/bn3.png)
  
这样在前向运算的时候，我们只需要在各卡上算出$$\sum x_i$$与$$\sum x_i^2$$，再跨卡求出全局的和即可得到正确的均值和方差，
同理我们在后向运算的时候只需同步一次，求出相应的梯度$$\frac{d_\ell}{\sum x_i}$$与$$\frac{d_\ell}{\sum x_i^2}$$。
我们在最近的论文[Context Encoding for Semantic Segmentation](https://arxiv.org/pdf/1803.08904.pdf)
里面也分享了这种同步一次的方法。

有了跨卡BN我们就不用担心模型过大用多卡影响收敛效果了，不管用多少张卡，都会得到相同的效果。

### 常见问答
- 模型是否可以 Hybridize？

  训练不行，测试可以。
  MXNet相对于其他平台的显著优势就是提供两套API接口，Symbol API提供静态图速度快，NDArray／Gluon API是impreative执行，
  接口简单好用，而且可以通过hybridize加速训练，这样无缝连接了两套接口。
  目前跨卡BN只提供Gluon接口，在训练时候不能hbridize，
  不过在训练完成之后，BatchNorm在inference的时候不需要跨卡，可以转成普通BN来hybridize。

- 能否使用Symbol API？

  目前不行。我们后台增加的operators都是支持Symbol和NDArray两个接口的，所以在构建图的时候完成跨卡操作在理论上是可行的。
  因为笔者是从Gluon API之后开始学习MXNet的，所以目前没有提供Symbol的调用方法，欢迎大家贡献解决方案。

- 训练是否会变慢，能否分布式训练？

  变慢是相对的，目前不能分布式。
  相同迭代次数的情况下，训练时间会变长，因为同步的锅（overhead），但是我们往往可以加大learning rate，
  因为有了跨卡BN，梯度更加平缓了。
  目前已经有相关论文里面说到实现了128卡的分布式训练，证明是可行的，根据竟然这个跨卡BN的latency主要来自于同步，更接近于一个常数，
  所以在大运算量，大网络面前，相对的overhead变得很小。目前我们这个版本还不支持，但是后面可能会做。

### [讨论点这里](https://discuss.gluon.ai/t/topic/1156)
